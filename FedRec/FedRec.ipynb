{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1fa4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:00:59.911702Z",
     "start_time": "2022-04-18T14:00:59.061132Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb6fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:00:59.927707Z",
     "start_time": "2022-04-18T14:00:59.913712Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_seed(seed, reproducibility):\n",
    "    r\"\"\" init random seed for random functions in numpy, torch, cuda and cudnn\n",
    "\n",
    "    Args:\n",
    "        seed (int): random seed\n",
    "        reproducibility (bool): Whether to require reproducibility\n",
    "    \"\"\"\n",
    "    #random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if reproducibility:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    else:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2e84b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:48:25.862437Z",
     "start_time": "2022-04-18T14:48:25.841929Z"
    }
   },
   "outputs": [],
   "source": [
    "def args_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # federated arguments\n",
    "    parser.add_argument('--epochs', type=int, default=100, help=\"rounds of training\")\n",
    "    parser.add_argument('--lr', type=float, default=0.8, help=\"learning rate\")\n",
    "    #parser.add_argument('--momentum', type=float, default=0.5, help=\"SGD momentum (default: 0.5)\")\n",
    "    parser.add_argument('--dim', type=int, default=20, help=\"latent dimension\")\n",
    "    parser.add_argument('--seed', type=int, default=2022, help='random seed (default: 2022)')\n",
    "    parser.add_argument('--alpha', type=float, default=1.0, help='alpha')\n",
    "    parser.add_argument('--Lambda', type=float, default=0.001, help='Lambda')\n",
    "    parser.add_argument('--topk', type=int, default=10, help='topk')\n",
    "    #parser.add_argument('--iterations', type=int, default=10, help='number of gradient descent iterations per epoch')\n",
    "    parser.add_argument('--local_train_iterations', type=int, default=5, help='local_train_iterations')\n",
    "    parser.add_argument('--start_hybrid_averaging_iterations', type=int, default=15, help='start_hybrid_averaging_iterations')\n",
    "    parser.add_argument('--rho', type=int, default=2, help='sample items')\n",
    "    parser.add_argument('--max_rating', type=float, default=5.0, help='max_rating')\n",
    "    parser.add_argument('--min_rating', type=float, default=1.0, help='min_rating')\n",
    "    parser.add_argument('-f', type=str, default=\"读取jupyter的额外参数\")\n",
    "    \n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341a7c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:26:57.762015Z",
     "start_time": "2022-04-18T14:26:57.747010Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8027ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:26:57.980899Z",
     "start_time": "2022-04-18T14:26:57.971953Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_sp_mat_to_sp_tensor(X):\n",
    "    coo = X.tocoo().astype(np.float32)\n",
    "    row = torch.Tensor(coo.row).long()\n",
    "    col = torch.Tensor(coo.col).long()\n",
    "    index = torch.stack([row, col])\n",
    "    data = torch.FloatTensor(coo.data)\n",
    "    return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))\n",
    "\n",
    "\n",
    "def get_all_pos(matrix, users):\n",
    "    items_pos = []\n",
    "    for user in users:\n",
    "        items_pos.append(matrix[user].nonzero()[1])\n",
    "    return items_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36259ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:26:58.166036Z",
     "start_time": "2022-04-18T14:26:58.154043Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(path, index=1):\n",
    "    train_path = path + 'copy' + str(index) + '.train'\n",
    "    test_path = path + 'copy' + str(index) + '.test'\n",
    "    num_users, num_items = 0, 0\n",
    "    train_user_dict = {}\n",
    "    train_user_ratings = {}\n",
    "    iteraction = 0\n",
    "    item_set = set()\n",
    "    with open(train_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split()\n",
    "            uid = int(line[0]) - 1\n",
    "            iid = int(line[1]) - 1\n",
    "            if train_user_dict.get(uid) == None:\n",
    "                train_user_dict[uid] = []\n",
    "                train_user_ratings[uid] = []\n",
    "            train_user_dict[uid].append(iid)\n",
    "            train_user_ratings[uid].append(float(line[2]))\n",
    "            item_set.add(iid)\n",
    "            iteraction += 1\n",
    "    test_user_dict = {}\n",
    "    test_user_ratings = {}\n",
    "    with open(test_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split()\n",
    "            uid = int(line[0]) - 1\n",
    "            if test_user_dict.get(uid) == None:\n",
    "                test_user_dict[uid] = []\n",
    "                test_user_ratings[uid] = []\n",
    "            test_user_dict[uid].append(int(line[1]) - 1)\n",
    "            test_user_ratings[uid].append(float(line[2]))\n",
    "            item_set.add(int(line[1]) - 1)\n",
    "    print(f'共有{len(train_user_dict)}个用户，{len(item_set)}个物品，交互总数为{iteraction}')\n",
    "    return train_user_dict, train_user_ratings, test_user_dict, test_user_ratings, len(train_user_dict), len(item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0892e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:26:58.368916Z",
     "start_time": "2022-04-18T14:26:58.345915Z"
    }
   },
   "outputs": [],
   "source": [
    "class FCF_client():\n",
    "    def __init__(self, uid, I, I_u, I_u_ratings, args):\n",
    "        super().__init__()\n",
    "        self.uid = uid\n",
    "        self.user_embedding = ((torch.rand(args.dim) - 0.5) * 0.01).to(device)\n",
    "        #self.user_embedding = torch.randn(args.dim).to(device)\n",
    "        self.args = args\n",
    "        self.lr = self.args.lr\n",
    "        self.I_u = np.array(I_u)\n",
    "        self.I_u_ratings = torch.tensor(I_u_ratings).to(device)\n",
    "        self.avg_r = np.sum(I_u_ratings) / self.I_u_ratings.shape[0]\n",
    "        self.I_u_sample = np.delete(I, self.I_u - 1)\n",
    "        self.iter = 0\n",
    "    \n",
    "    def train(self, item_embeddings):\n",
    "        loss = 0.0\n",
    "        u_item_embeddings = item_embeddings[self.I_u]\n",
    "        pred = self.user_embedding @ u_item_embeddings.T\n",
    "        err = self.I_u_ratings - pred\n",
    "        loss += torch.sum(err.pow(2)).item()\n",
    "        grad_u = -(err.reshape(-1, 1) * u_item_embeddings).sum(0) + self.args.Lambda * self.I_u.shape[0] * self.user_embedding\n",
    "        grad_i = -err.reshape(-1, 1) * self.user_embedding + self.args.Lambda * u_item_embeddings\n",
    "        temp_u = 0\n",
    "        \n",
    "        \n",
    "        if self.args.rho != 0:\n",
    "            if self.iter > self.args.start_hybrid_averaging_iterations:\n",
    "                temp_u = self.user_embedding.clone()\n",
    "                for it in range(self.args.local_train_iterations):\n",
    "                    pred = temp_u @ u_item_embeddings.T\n",
    "                    err = self.I_u_ratings - pred\n",
    "                    temp_grad_u = -(err.reshape(-1, 1) * u_item_embeddings).sum(0) + self.args.Lambda * self.I_u.shape[0] * temp_u\n",
    "                    temp_u = temp_u - self.lr * temp_grad_u / self.I_u.shape[0]\n",
    "        \n",
    "        \n",
    "        sample_number = self.args.rho * self.I_u.shape[0] if self.args.rho * self.I_u.shape[0] < self.I_u_sample.shape[0] else self.I_u_sample.shape[0]\n",
    "                                     \n",
    "        np.random.shuffle(self.I_u_sample)\n",
    "        update_list = np.append(self.I_u, self.I_u_sample[:sample_number])\n",
    "        \n",
    "        sample_item_emb = item_embeddings[self.I_u_sample[:sample_number]]\n",
    "        pred = self.user_embedding @ sample_item_emb.T\n",
    "        if self.iter > self.args.start_hybrid_averaging_iterations:\n",
    "            temp_pred = temp_u @ sample_item_emb.T\n",
    "            err = temp_pred - pred\n",
    "        else:\n",
    "            err = torch.tensor([self.avg_r] * sample_number).to(device) - pred\n",
    "        loss += torch.sum(err.pow(2)).item()\n",
    "        grad_u += -(err.reshape(-1, 1) * sample_item_emb).sum(0) + self.args.Lambda * sample_number * self.user_embedding\n",
    "        grad_sample_i = -err.reshape(-1, 1) * self.user_embedding + self.args.Lambda * sample_item_emb\n",
    "        self.user_embedding -= self.lr * grad_u / (self.I_u.shape[0] + sample_number)\n",
    "        self.lr *= 0.9\n",
    "        self.iter += 1\n",
    "        #print(self.user_embedding)\n",
    "        return loss, update_list, torch.cat((grad_i, grad_sample_i), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e4924",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:26:58.587986Z",
     "start_time": "2022-04-18T14:26:58.569982Z"
    }
   },
   "outputs": [],
   "source": [
    "class FCF_server(nn.Module):\n",
    "    def __init__(self, args, num_items):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.num_items = num_items\n",
    "        self.item_embeddings = ((torch.rand(num_items, args.dim)-0.5)*0.01).to(device)\n",
    "        #self.item_embeddings = torch.randn(num_items, args.dim).to(device)\n",
    "        self.lr = self.args.lr\n",
    "        \n",
    "    def update(self, sum_grad_i, count_i):\n",
    "        count_i[count_i < 1] = 1\n",
    "        count_i = torch.tensor(count_i).reshape(-1,1).to(device)\n",
    "        self.item_embeddings -= self.lr * sum_grad_i / count_i\n",
    "        self.lr *= 0.9\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e719293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:26:58.946032Z",
     "start_time": "2022-04-18T14:26:58.940030Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(test_user_dict, test_user_ratings, server_model, users_model, args):\n",
    "    with torch.no_grad():\n",
    "        rmse = 0.0\n",
    "        mae = 0.0\n",
    "        item_cnt = 0\n",
    "        for user in test_user_dict:\n",
    "            items = test_user_dict[user]\n",
    "            ratings = torch.tensor(test_user_ratings[user]).to(device)\n",
    "            pred = users_model[user].user_embedding @ server_model.item_embeddings[items].T\n",
    "\n",
    "            pred[pred < args.min_rating] = args.min_rating\n",
    "            pred[pred > args.max_rating] = args.max_rating\n",
    "            rmse += torch.sum((ratings - pred).pow(2))\n",
    "            mae += torch.sum((ratings - pred).abs())\n",
    "            item_cnt += len(items)\n",
    "        rmse = math.sqrt(rmse / item_cnt)\n",
    "        mae = mae / item_cnt\n",
    "        return rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cb4090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:26:59.260832Z",
     "start_time": "2022-04-18T14:26:59.244563Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainer(index=5, path='./ML100K/'):\n",
    "    args = args_parser()\n",
    "    init_seed(args.seed, True)\n",
    "    rmse_l, mae_l = [], []\n",
    "    for idx in range(1, 1+index):\n",
    "        rmse_min, mae_min = 1<<20, 1<<20\n",
    "        args = args_parser()\n",
    "        train_user_dict, train_user_ratings, test_user_dict, test_user_ratings, num_users, num_items = read_data(path, idx)\n",
    "        users_model = []\n",
    "        server_model = FCF_server(args, num_items)\n",
    "        I = np.arange(0, num_items)\n",
    "        for uid in range(num_users):\n",
    "            users_model.append(FCF_client(uid, I, train_user_dict[uid], train_user_ratings[uid], args))\n",
    "        for epoch in range(args.epochs):\n",
    "            sum_loss = 0.0\n",
    "            cnt_items = 0\n",
    "            sum_grad_i = torch.zeros(num_items, args.dim).to(device)\n",
    "            count_i = np.zeros(num_items)\n",
    "            for uid in range(num_users):\n",
    "            #for uid in range(1):\n",
    "                loss, update_list, grad_i = users_model[uid].train(server_model.item_embeddings)\n",
    "                sum_loss += loss\n",
    "                sum_grad_i[update_list] += grad_i\n",
    "                count_i[update_list] += 1\n",
    "                cnt_items += update_list.shape[0]\n",
    "            server_model.update(sum_grad_i, count_i)\n",
    "            sum_loss = math.sqrt(sum_loss / cnt_items)\n",
    "            print(f'Epoch {epoch+1}/{args.epochs}: rmse {sum_loss:.8f}')\n",
    "            rmse, mae = test(test_user_dict, test_user_ratings, server_model, users_model, args)\n",
    "            print(f'Test rmse {rmse:.8f}, mae {mae:.8f}')\n",
    "            rmse_min = min(rmse_min, rmse)\n",
    "            mae_min = min(mae_min, mae.item())\n",
    "        print(f'Best rmse {rmse_min:.8f}, mae {mae_min:.8f}')\n",
    "        rmse_l.append(rmse_min)\n",
    "        mae_l.append(mae_min)\n",
    "    rmse_l = np.array(rmse_l)\n",
    "    mae_l = np.array(mae_l)\n",
    "    print(f'RMSE: {np.mean(rmse_l):.5f}±{np.std(rmse_l):.5f}')\n",
    "    print(f'MAE : {np.mean(mae_l):.5f}±{np.std(mae_l):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6755de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T14:45:10.335691Z",
     "start_time": "2022-04-18T14:26:59.676019Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer(5, './ML100K/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fee0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
